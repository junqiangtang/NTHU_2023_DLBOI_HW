{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Li0bVCTuxc6n"
   },
   "source": [
    "<div align=\"center\">\n",
    "\n",
    "# National Tsing Hua University\n",
    "\n",
    "### Fall 2023\n",
    "\n",
    "#### 11210IPT 553000\n",
    "\n",
    "#### Deep Learning in Biomedical Optical Imaging\n",
    "\n",
    "## Report\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mGJcRwdzM7pS"
   },
   "outputs": [],
   "source": [
    "# Download train and val dataset\n",
    "!wget -q -O report_train.npy \"https://www.dropbox.com/scl/fi/30dlbblp7wytcvoy05col/report_train.npy?rlkey=jx100qoz5n1d654v2mi32i9aj&dl=1\"\n",
    "!wget -q -O report_val.npy \"https://www.dropbox.com/scl/fi/oo6g1yqhbjm22wffeddgv/report_val.npy?rlkey=9rqe0rucjhrbzv3x7xbs5047z&dl=1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w-1PsC--M7pT"
   },
   "source": [
    "## A. Data Loading and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oScQ0GG6xc6r"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
    "import numpy as np\n",
    "\n",
    "# Load Dataset\n",
    "x_train = np.transpose(np.load('report_train.npy'), (0, 3, 1, 2))\n",
    "x_val = np.transpose(np.load('report_val.npy'), (0, 3, 1, 2))\n",
    "\n",
    "print(f'Shape of x_train: {x_train.shape}')\n",
    "print(f'Shape of x_val: {x_val.shape}')\n",
    "\n",
    "num_classes = 6\n",
    "\n",
    "# Create labels\n",
    "y_train = np.concatenate([np.full(425, i) for i in range(num_classes)])\n",
    "y_val = np.concatenate([np.full(100, i) for i in range(num_classes)])\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "x_train = torch.from_numpy(x_train).float()\n",
    "y_train = torch.from_numpy(y_train).long()\n",
    "\n",
    "x_val = torch.from_numpy(x_val).float()\n",
    "y_val = torch.from_numpy(y_val).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = TensorDataset(x_train, y_train)\n",
    "val_dataset = TensorDataset(x_val, y_val)\n",
    "\n",
    "# Create dataloaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "print(f'Number of samples in train and validation are {len(train_loader.dataset)} and {len(val_loader.dataset)}.')\n",
    "print(f'X_train: max value is {x_train.max().item()}, min value is {x_train.min().item()}, data type is {x_train.dtype}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "class_names = ['Tumor', 'Stroma', 'Complex', 'Lympho', 'Debris', 'Mucosa']\n",
    "\n",
    "num_classes = 6\n",
    "samples_per_class = 3\n",
    "\n",
    "fig, axes = plt.subplots(samples_per_class, num_classes, figsize=(12, 6))\n",
    "\n",
    "plt.subplots_adjust(left=0.05, right=0.95, bottom=0.05, top=0.95, wspace=0.1, hspace=0.1)\n",
    "\n",
    "for class_idx in range(num_classes):\n",
    "    indices_of_class = np.where(y_train == class_idx)[0]\n",
    "    random_indices = random.sample(list(indices_of_class), samples_per_class)\n",
    "    \n",
    "    for i in range(samples_per_class):\n",
    "        ax = axes[i, class_idx]\n",
    "        img = x_train[random_indices[i]].numpy().transpose((1, 2, 0))\n",
    "        img = img / img.max() \n",
    "        ax.imshow(img)\n",
    "        ax.axis('off')  \n",
    "        \n",
    "        if i == 0:\n",
    "            ax.set_title(f'{class_idx} {class_names[class_idx]}', pad=3)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oaLGtT28xc6s"
   },
   "source": [
    "## B. Defining Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nvLTU-IfZLqn"
   },
   "source": [
    "## C. Training the Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "45ol4lpVxc6t"
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR, StepLR\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pjmYxAJnxc6t"
   },
   "source": [
    "### Visualizing model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pHpS0Q7vxc6t"
   },
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# # Plotting training and validation accuracy\n",
    "# ax[0].plot(train_accuracies)\n",
    "# ax[0].plot(val_accuracies)\n",
    "# ax[0].set_title('Model Accuracy')\n",
    "# ax[0].set_xlabel('Epochs')\n",
    "# ax[0].set_ylabel('Accuracy')\n",
    "# ax[0].legend(['Train', 'Val'])\n",
    "\n",
    "# # Plotting training and validation loss\n",
    "# ax[1].plot(train_losses)\n",
    "# ax[1].plot(val_losses)\n",
    "# ax[1].set_title('Model Loss')\n",
    "# ax[1].set_xlabel('Epochs')\n",
    "# ax[1].set_ylabel('Loss')\n",
    "# ax[1].legend(['Train', 'Val'])\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## D. Evaluating Your Trained Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Process Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download test dataset, \n",
    "!wget -q -O report_test.npy \"https://www.dropbox.com/scl/fi/ufcagx2cvjmervgqrgwrt/report_test.npy?rlkey=fijueom5x54628ivpzeki2bt0&dl=1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = np.transpose(np.load('report_test.npy'), (0, 3, 1, 2))\n",
    "print(f'Shape of x_test: {x_test.shape}')\n",
    "\n",
    "y_test = np.concatenate([np.full(100, i) for i in range(num_classes)])\n",
    "\n",
    "x_test = torch.from_numpy(x_test).float()\n",
    "y_test = torch.from_numpy(y_test).long()\n",
    "\n",
    "print(f'x_test: max value is {x_test.max().item()}, min value is {x_test.min().item()}, data type is {x_test.dtype}.')\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "# Combine the images and labels into a dataset\n",
    "test_dataset = TensorDataset(x_test, y_test)\n",
    "\n",
    "# Create a dataloader to load data in batches. Set batch size to 32.\n",
    "test_loader = DataLoader(test_dataset, batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Trained Model and Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
